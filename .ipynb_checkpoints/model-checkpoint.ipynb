{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d638a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "import neattext as ntx\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf84c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/data.csv')\n",
    "data = pd.read_csv('datasets/less_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be591bdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>type</th>\n",
       "      <th>post_created_at</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>info_tweet</th>\n",
       "      <th>followers_group</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32573198</td>\n",
       "      <td>430716388483682304</td>\n",
       "      <td>Happy birthday to my nephew @Tyy_FFOE no matte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-02-04 14:56:04+00:00</td>\n",
       "      <td>105</td>\n",
       "      <td>358</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>happy birthday nephew mat old old do back lov bud</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91649490</td>\n",
       "      <td>301312699583827968</td>\n",
       "      <td>They may look alike, but Kevin Saunders &amp;gt; C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2013-02-12 12:52:00+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>look alik kevin saund gt chuck nor #emaw #kstate</td>\n",
       "      <td>['#EMAW', '#KSTATE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42791233</td>\n",
       "      <td>2503205825</td>\n",
       "      <td>Some Interesting Bat Stories http://bit.ly/MrGUI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2009-07-06 21:18:32+00:00</td>\n",
       "      <td>170</td>\n",
       "      <td>57</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>interest bat story</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79969596</td>\n",
       "      <td>1541356927455739904</td>\n",
       "      <td>Does #ClarenceThomas wife use They/Them #prono...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2022-06-27 09:45:03+00:00</td>\n",
       "      <td>337</td>\n",
       "      <td>8664</td>\n",
       "      <td>3685</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>#clarencethomas wif us they/them #pronouns</td>\n",
       "      <td>['#ClarenceThomas', '#pronouns']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64686970</td>\n",
       "      <td>1544667602886135808</td>\n",
       "      <td>Wow! what a view? Don't you agree?   The aweso...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2022-07-06 13:00:29+00:00</td>\n",
       "      <td>5050</td>\n",
       "      <td>399</td>\n",
       "      <td>2694</td>\n",
       "      <td>3</td>\n",
       "      <td>Middle</td>\n",
       "      <td>wow view agr awesom beach prevel palm forest b...</td>\n",
       "      <td>['#Crete', '#VisitCrete', '#Greece', '#VisitGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38661</th>\n",
       "      <td>22990132</td>\n",
       "      <td>423833471514337280</td>\n",
       "      <td>I posted a new photo to Facebook http://t.co/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-01-16 15:05:48+00:00</td>\n",
       "      <td>463</td>\n",
       "      <td>1051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>post new photo facebook</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38662</th>\n",
       "      <td>47882200</td>\n",
       "      <td>532297384634884097</td>\n",
       "      <td>I posted a new photo to Facebook http://t.co/c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-11-11 22:22:40+00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>2683</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>post new photo facebook</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38663</th>\n",
       "      <td>75926261</td>\n",
       "      <td>4136358503</td>\n",
       "      <td>I'm not sure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2009-09-21 01:27:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Many</td>\n",
       "      <td>im sur</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38664</th>\n",
       "      <td>61070970</td>\n",
       "      <td>1498433391582408705</td>\n",
       "      <td>Americansâ€™ main sources for political news var...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2022-02-28 23:02:14+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>1943</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>am main sourc polit new vary party ag</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38665</th>\n",
       "      <td>52472617</td>\n",
       "      <td>247418381534380033</td>\n",
       "      <td>Cool! I earned $74.13 so far by doing surveys!...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2012-09-16 19:35:13+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>cool earn $7413 far survey excit mor look gt</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38666 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id              text_id  \\\n",
       "0      32573198   430716388483682304   \n",
       "1      91649490   301312699583827968   \n",
       "2      42791233           2503205825   \n",
       "3      79969596  1541356927455739904   \n",
       "4      64686970  1544667602886135808   \n",
       "...         ...                  ...   \n",
       "38661  22990132   423833471514337280   \n",
       "38662  47882200   532297384634884097   \n",
       "38663  75926261           4136358503   \n",
       "38664  61070970  1498433391582408705   \n",
       "38665  52472617   247418381534380033   \n",
       "\n",
       "                                                    text  retweet_count  \\\n",
       "0      Happy birthday to my nephew @Tyy_FFOE no matte...              0   \n",
       "1      They may look alike, but Kevin Saunders &gt; C...              0   \n",
       "2       Some Interesting Bat Stories http://bit.ly/MrGUI              0   \n",
       "3      Does #ClarenceThomas wife use They/Them #prono...              0   \n",
       "4      Wow! what a view? Don't you agree?   The aweso...              1   \n",
       "...                                                  ...            ...   \n",
       "38661  I posted a new photo to Facebook http://t.co/r...              0   \n",
       "38662  I posted a new photo to Facebook http://t.co/c...              0   \n",
       "38663                                       I'm not sure              0   \n",
       "38664  Americansâ€™ main sources for political news var...              0   \n",
       "38665  Cool! I earned $74.13 so far by doing surveys!...              0   \n",
       "\n",
       "       reply_count  like_count  quote_count lang   type  \\\n",
       "0                0           0            0   en  tweet   \n",
       "1                0           0            0   en  tweet   \n",
       "2                0           0            0   en  tweet   \n",
       "3                0           0            0   en  tweet   \n",
       "4                0           2            0   en  tweet   \n",
       "...            ...         ...          ...  ...    ...   \n",
       "38661            0           0            0   en  tweet   \n",
       "38662            0           0            0   en  tweet   \n",
       "38663            0           0            0   en  tweet   \n",
       "38664            0           0            0   en  tweet   \n",
       "38665            0           0            0   en  tweet   \n",
       "\n",
       "                 post_created_at  followers_count  statuses_count  \\\n",
       "0      2014-02-04 14:56:04+00:00              105             358   \n",
       "1      2013-02-12 12:52:00+00:00               15             124   \n",
       "2      2009-07-06 21:18:32+00:00              170              57   \n",
       "3      2022-06-27 09:45:03+00:00              337            8664   \n",
       "4      2022-07-06 13:00:29+00:00             5050             399   \n",
       "...                          ...              ...             ...   \n",
       "38661  2014-01-16 15:05:48+00:00              463            1051   \n",
       "38662  2014-11-11 22:22:40+00:00               33            2683   \n",
       "38663  2009-09-21 01:27:14+00:00                1               9   \n",
       "38664  2022-02-28 23:02:14+00:00               35            1943   \n",
       "38665  2012-09-16 19:35:13+00:00                9              43   \n",
       "\n",
       "       friends_count  info_tweet followers_group  \\\n",
       "0                153           0             Low   \n",
       "1                 72           0             Low   \n",
       "2                451           0             Low   \n",
       "3               3685           0             Low   \n",
       "4               2694           3          Middle   \n",
       "...              ...         ...             ...   \n",
       "38661              0           0             Low   \n",
       "38662             74           0             Low   \n",
       "38663              0           0            Many   \n",
       "38664            293           0             Low   \n",
       "38665              0           0             Low   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0      happy birthday nephew mat old old do back lov bud   \n",
       "1       look alik kevin saund gt chuck nor #emaw #kstate   \n",
       "2                                     interest bat story   \n",
       "3             #clarencethomas wif us they/them #pronouns   \n",
       "4      wow view agr awesom beach prevel palm forest b...   \n",
       "...                                                  ...   \n",
       "38661                            post new photo facebook   \n",
       "38662                            post new photo facebook   \n",
       "38663                                             im sur   \n",
       "38664              am main sourc polit new vary party ag   \n",
       "38665       cool earn $7413 far survey excit mor look gt   \n",
       "\n",
       "                                                hashtags  \n",
       "0                                                     []  \n",
       "1                                   ['#EMAW', '#KSTATE']  \n",
       "2                                                     []  \n",
       "3                       ['#ClarenceThomas', '#pronouns']  \n",
       "4      ['#Crete', '#VisitCrete', '#Greece', '#VisitGr...  \n",
       "...                                                  ...  \n",
       "38661                                                 []  \n",
       "38662                                                 []  \n",
       "38663                                                 []  \n",
       "38664                                                 []  \n",
       "38665                                                 []  \n",
       "\n",
       "[38666 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc1d334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6                1242778877\n",
       "9                6993457307\n",
       "10       107726865678090240\n",
       "18               1923353496\n",
       "20        61976209596223488\n",
       "                ...        \n",
       "38654    178081911657340932\n",
       "38656    264665041775779840\n",
       "38659            6324367727\n",
       "38663            4136358503\n",
       "38665    247418381534380033\n",
       "Name: text_id, Length: 8906, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['info_tweet'] == 0) & (data['followers_count'] < 10)]['text_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94093d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_values = np.random.choice(data[(data['info_tweet'] == 0) & (data['followers_count'] < 10)]['text_id'], 4000)\n",
    "drop_values = np.random.choice(data[data['info_tweet'] == 0]['text_id'], 8000)\n",
    "\n",
    "data = data[~data['text_id'].isin(drop_values)]\n",
    "data.index = range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe7a5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['type'] == 'tweet']\n",
    "# data = data[data['lang'] == 'en']\n",
    "# data.index = range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f67f79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stemmer = LancasterStemmer()\n",
    "\n",
    "# def remove_emojis(data):\n",
    "#     emoj = re.compile(\"[\"\n",
    "#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#         u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "#         u\"\\U00002702-\\U000027B0\"\n",
    "#         u\"\\U00002702-\\U000027B0\"\n",
    "#         u\"\\U000024C2-\\U0001F251\"\n",
    "#         u\"\\U0001f926-\\U0001f937\"\n",
    "#         u\"\\U00010000-\\U0010ffff\"\n",
    "#         u\"\\u2640-\\u2642\" \n",
    "#         u\"\\u2600-\\u2B55\"\n",
    "#         u\"\\u200d\"\n",
    "#         u\"\\u23cf\"\n",
    "#         u\"\\u23e9\"\n",
    "#         u\"\\u231a\"\n",
    "#         u\"\\ufe0f\"  # dingbats\n",
    "#         u\"\\u3030\"\n",
    "#                       \"]+\", re.UNICODE)\n",
    "#     return re.sub(emoj, '', data)\n",
    "\n",
    "# def stem_sentence(text):\n",
    "#     text = [stemmer.stem(word) for word in text.split()]\n",
    "    \n",
    "#     return ' '.join(text)\n",
    "    \n",
    "    \n",
    "# data['clean_text'] = data['text'].apply(lambda x: ntx.remove_stopwords(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_userhandles(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_urls(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_punctuations(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_multiple_spaces(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: remove_emojis(x))\n",
    "\n",
    "# data['hashtags'] = data['clean_text'].apply(lambda x: ntx.extract_hashtags(x))\n",
    "# # data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_hashtags(x))\n",
    "\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: stem_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee966eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am lay feet im humbl wond majesty thing know find nee unend lov\n",
      "Now all I am, I lay at Your feet I'm humbled by the wonder of Your majesty, one thing I know I find all I need in Your Unending Love.\n"
     ]
    }
   ],
   "source": [
    "print(data['clean_text'][0])\n",
    "print(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb235f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean text: 11944 sentences with numbers\n",
      "Text: 27607 sentences with numbers\n"
     ]
    }
   ],
   "source": [
    "def number_in_text(text, number):\n",
    "    for i in number:\n",
    "        if i in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "a = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print('Clean text:', data['clean_text'].apply(lambda x: number_in_text(x,a)).sum(), 'sentences with numbers')\n",
    "print('Text:', data['text'].apply(lambda x: number_in_text(x,a)).sum(), 'sentences with numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "87062154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# less_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# ind = np.random.randint(0, data.index[-1]+1, 42000)\n",
    "# less_data = data.loc[ind]\n",
    "\n",
    "# less_data.to_csv('datasets/less_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2068ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['retweet_count', 'like_count', 'quote_count']].copy()\n",
    "y['retweets'] = y['retweet_count'] + y['quote_count']\n",
    "y.drop(['retweet_count', 'quote_count'], axis=1, inplace=True)\n",
    "\n",
    "x_col = ['followers_count', 'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177735bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TEXT\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorized_text = vectorizer.fit_transform(data['clean_text'])\n",
    "vectorized_text = vectorized_text.astype(np.float32)\n",
    "vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "\n",
    "# vectorizer = CountVectorizer(binary=True, dtype=np.int32)\n",
    "\n",
    "# vectorized_text = vectorizer.fit_transform(data['clean_text']).toarray()\n",
    "vectorized_text_with_followers = np.insert(vectorized_text, 0, data['followers_count'], axis=1) \n",
    "del vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e872c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes too much memory\n",
    "\n",
    "scaler = StandardScaler()\n",
    "to_input = scaler.fit_transform(vectorized_text_with_followers)\n",
    "to_input = to_input.astype(np.float16)\n",
    "del vectorized_text_with_followers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e227b",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf164b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "model.fit(to_input, y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3705c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617042825415429"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(to_input, y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01903096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "# model.fit(vectorized_text_with_followers, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab48ce83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load('filename.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af973609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19682</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>5617</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29319</th>\n",
       "      <td>5646</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>8262</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26639</th>\n",
       "      <td>16299</td>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21220</th>\n",
       "      <td>61238</td>\n",
       "      <td>69561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39365 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       like_count  retweets\n",
       "19682           0         0\n",
       "21098           0         0\n",
       "21097           0         0\n",
       "21096           0         0\n",
       "21095           0         0\n",
       "...           ...       ...\n",
       "5435         5617       188\n",
       "29319        5646       112\n",
       "10298        8262      1705\n",
       "26639       16299      2448\n",
       "21220       61238     69561\n",
       "\n",
       "[39365 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sort_values(by='like_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da07ff",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc148aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01749  -0.0385   -0.005615 ... -0.005615 -0.005615 -0.005615]]\n",
      "[[-27.94318497  -1.06780788]]\n",
      "id                                                          92368524\n",
      "text_id                                           550856412822122496\n",
      "text               Ran 3.1 miles today to officially start my Run...\n",
      "retweet_count                                                      0\n",
      "reply_count                                                        0\n",
      "like_count                                                         0\n",
      "quote_count                                                        0\n",
      "lang                                                              en\n",
      "type                                                           tweet\n",
      "post_created_at                            2015-01-02 03:29:37+00:00\n",
      "followers_count                                                   36\n",
      "statuses_count                                                   502\n",
      "friends_count                                                    181\n",
      "info_tweet                                                         0\n",
      "followers_group                                                  Low\n",
      "clean_text         ran 31 mil today off start run day 2015 challe...\n",
      "hashtags                                 ['#2015runthedaychallenge']\n",
      "Name: 15, dtype: object\n",
      "like_count    0\n",
      "retweets      0\n",
      "Name: 15, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "\n",
    "# print(np.array([1543952 if i == 0 else 0 for i in \\\n",
    "#                               range(len(to_input[n]))])[np.newaxis, :])\n",
    "print(to_input[n][np.newaxis, :])\n",
    "print(model.predict(to_input[n][np.newaxis, :]))\n",
    "# print(model.predict(np.array([1543952 if i == 0 else 0 for i in \\\n",
    "#                               range(len(to_input[n]))])[np.newaxis, :]))\n",
    "print(data.loc[n])\n",
    "print(y.loc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5602bdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22603536062221866"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['info_tweet'] > 0]) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5b870",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK BAD IDEA, BECAUSE WE NEED SUCH A POWER COMPUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344d6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, return_sequences=True, input_shape=(1, vectorized_text.shape[-1])))\n",
    "# model.add(LSTM(50))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6316d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d5d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1559/1559 [==============================] - 69s 42ms/step - loss: 761319.4375\n",
      "Epoch 2/15\n",
      " 453/1559 [=======>......................] - ETA: 45s - loss: 203298.9375"
     ]
    }
   ],
   "source": [
    "# model.fit(vectorized_text[:, np.newaxis, :], y, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ff723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58ecde",
   "metadata": {},
   "source": [
    "## HASHTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take_unique_hashtags(ser):\n",
    "#     unique = []\n",
    "#     for lis in ser:\n",
    "#         for hashtag in lis:\n",
    "#             if hashtag not in unique:\n",
    "#                 unique.append(hashtag)\n",
    "    \n",
    "#     return unique\n",
    "\n",
    "# data['hashtags'] = clear_hashtags(data['hashtags'].copy())\n",
    "# unique_hashtags = take_unique_hashtags(data['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2075ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ########## HASHTAGS\n",
    "\n",
    "\n",
    "# vectorize_hash = TfidfVectorizer()\n",
    "\n",
    "# # vectorized_hash_fited = vectorize_hash.fit_transform(data['hashtags'])\n",
    "# # vectorized_hash_fited = vectorized_hash_fited.astype(np.float16)\n",
    "# # vectorized_hash_fited = vectorized_hash_fited.toarray()\n",
    "\n",
    "# vectorize_hash.fit(unique_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_of_hash_uniq = len(vectorize_hash.get_feature_names_out())\n",
    "\n",
    "# def convert_hashtag_to_vector(hashtags, vectorizer, len_of_features):\n",
    "#     ones = np.ones((len_of_features))\n",
    "#     if len(hashtags) == 1:\n",
    "#         ind = np.argmax(vectorizer.transform(hashtags))\n",
    "#         ones[ind] = 1\n",
    "#     elif len(hashtags) >= 2:\n",
    "#         indexes = []\n",
    "#         for hashtag in hashtags:\n",
    "#             indexes.append(np.argmax(vectorizer.transform([hashtag])))\n",
    "#         for index in indexes:\n",
    "#             ones[index] = 1\n",
    "        \n",
    "#     return ones\n",
    "\n",
    "        \n",
    "# # vectorize_hash.transform(['#hello']).toarray()\n",
    "# data['hashtags'] = data['hashtags'].apply(lambda x: convert_hashtag_to_vector(x, vectorize_hash, len_of_hash_uniq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
