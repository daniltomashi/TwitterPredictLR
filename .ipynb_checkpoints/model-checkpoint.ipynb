{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d638a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import neattext as ntx\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf84c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/data.csv')\n",
    "data = pd.read_csv('datasets/less_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be591bdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>type</th>\n",
       "      <th>post_created_at</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>info_tweet</th>\n",
       "      <th>followers_group</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15333677</td>\n",
       "      <td>584512767803133952</td>\n",
       "      <td>Now all I am, I lay at Your feet I'm humbled b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-04-05 00:27:58+00:00</td>\n",
       "      <td>174</td>\n",
       "      <td>3215</td>\n",
       "      <td>284</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>am lay feet im humbl wond majesty thing know f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19087660</td>\n",
       "      <td>477548826283503617</td>\n",
       "      <td>Did Iker have a Ronaldo style seizure before t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-06-13 20:31:27+00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>675</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>ik ronaldo styl seiz gam hes play match lik he...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53497708</td>\n",
       "      <td>918610033113489409</td>\n",
       "      <td>But like how are we supposed to study when we ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-10-12 22:51:13+00:00</td>\n",
       "      <td>435</td>\n",
       "      <td>11330</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Low</td>\n",
       "      <td>lik suppos study 9+ hour paperwork tim</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68372499</td>\n",
       "      <td>516872862205231104</td>\n",
       "      <td>'I know you can only change when you build goo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-09-30 08:51:08+00:00</td>\n",
       "      <td>76</td>\n",
       "      <td>992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>i know chang build good habit that forward jos...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40700737</td>\n",
       "      <td>194032647918465024</td>\n",
       "      <td>I'm at Borsa Restaurant (Istanbul, Turkey) htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2012-04-22 11:59:22+00:00</td>\n",
       "      <td>46</td>\n",
       "      <td>5983</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>im bors resta (istanbul turkey)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49913</th>\n",
       "      <td>32602656</td>\n",
       "      <td>1009808459712385027</td>\n",
       "      <td>.@okc_aft and @okea is there a list of candida...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2018-06-21 14:41:12+00:00</td>\n",
       "      <td>40</td>\n",
       "      <td>93</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>list candid endors prim avail somewh</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49914</th>\n",
       "      <td>27342769</td>\n",
       "      <td>1535917357645762560</td>\n",
       "      <td>It might be rather easy to push your buttons t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2022-06-12 09:30:08+00:00</td>\n",
       "      <td>238</td>\n",
       "      <td>6902</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>easy push button today scorpio t scorpio</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49915</th>\n",
       "      <td>42541403</td>\n",
       "      <td>351458293698412544</td>\n",
       "      <td>Vintage Photos: How Your Patio Would Have Look...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2013-06-30 21:52:41+00:00</td>\n",
       "      <td>963</td>\n",
       "      <td>1451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>vint photos: patio look 40s</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49916</th>\n",
       "      <td>14661985</td>\n",
       "      <td>157104202135506944</td>\n",
       "      <td>Weird! Image of Virgin Mary appears at Ybor di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2012-01-11 14:18:55+00:00</td>\n",
       "      <td>381</td>\n",
       "      <td>2462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>weird im virgin mary appear yb diner: custom r...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49917</th>\n",
       "      <td>51097581</td>\n",
       "      <td>870205980415537152</td>\n",
       "      <td>Cuteness in sickness . . . #cat #blackcat http...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-06-01 09:10:48+00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>2020</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>cut sick #cat #blackcat</td>\n",
       "      <td>['#cat', '#blackcat']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49918 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id              text_id  \\\n",
       "0      15333677   584512767803133952   \n",
       "1      19087660   477548826283503617   \n",
       "2      53497708   918610033113489409   \n",
       "3      68372499   516872862205231104   \n",
       "4      40700737   194032647918465024   \n",
       "...         ...                  ...   \n",
       "49913  32602656  1009808459712385027   \n",
       "49914  27342769  1535917357645762560   \n",
       "49915  42541403   351458293698412544   \n",
       "49916  14661985   157104202135506944   \n",
       "49917  51097581   870205980415537152   \n",
       "\n",
       "                                                    text  retweet_count  \\\n",
       "0      Now all I am, I lay at Your feet I'm humbled b...              1   \n",
       "1      Did Iker have a Ronaldo style seizure before t...              1   \n",
       "2      But like how are we supposed to study when we ...              0   \n",
       "3      'I know you can only change when you build goo...              0   \n",
       "4      I'm at Borsa Restaurant (Istanbul, Turkey) htt...              0   \n",
       "...                                                  ...            ...   \n",
       "49913  .@okc_aft and @okea is there a list of candida...              0   \n",
       "49914  It might be rather easy to push your buttons t...              0   \n",
       "49915  Vintage Photos: How Your Patio Would Have Look...              0   \n",
       "49916  Weird! Image of Virgin Mary appears at Ybor di...              0   \n",
       "49917  Cuteness in sickness . . . #cat #blackcat http...              0   \n",
       "\n",
       "       reply_count  like_count  quote_count lang   type  \\\n",
       "0                0           1            0   en  tweet   \n",
       "1                1           0            0   en  tweet   \n",
       "2                2           4            0   en  tweet   \n",
       "3                0           0            0   en  tweet   \n",
       "4                0           0            0   en  tweet   \n",
       "...            ...         ...          ...  ...    ...   \n",
       "49913            0           1            0   en  tweet   \n",
       "49914            0           0            0   en  tweet   \n",
       "49915            0           0            0   en  tweet   \n",
       "49916            0           0            0   en  tweet   \n",
       "49917            0           1            0   en  tweet   \n",
       "\n",
       "                 post_created_at  followers_count  statuses_count  \\\n",
       "0      2015-04-05 00:27:58+00:00              174            3215   \n",
       "1      2014-06-13 20:31:27+00:00               32             675   \n",
       "2      2017-10-12 22:51:13+00:00              435           11330   \n",
       "3      2014-09-30 08:51:08+00:00               76             992   \n",
       "4      2012-04-22 11:59:22+00:00               46            5983   \n",
       "...                          ...              ...             ...   \n",
       "49913  2018-06-21 14:41:12+00:00               40              93   \n",
       "49914  2022-06-12 09:30:08+00:00              238            6902   \n",
       "49915  2013-06-30 21:52:41+00:00              963            1451   \n",
       "49916  2012-01-11 14:18:55+00:00              381            2462   \n",
       "49917  2017-06-01 09:10:48+00:00               32            2020   \n",
       "\n",
       "       friends_count  info_tweet followers_group  \\\n",
       "0                284           2             Low   \n",
       "1                 88           2             Low   \n",
       "2                  0           6             Low   \n",
       "3                  0           0             Low   \n",
       "4                 32           0             Low   \n",
       "...              ...         ...             ...   \n",
       "49913            359           1             Low   \n",
       "49914            406           0             Low   \n",
       "49915              0           0             Low   \n",
       "49916              0           0             Low   \n",
       "49917             98           1             Low   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0      am lay feet im humbl wond majesty thing know f...   \n",
       "1      ik ronaldo styl seiz gam hes play match lik he...   \n",
       "2                 lik suppos study 9+ hour paperwork tim   \n",
       "3      i know chang build good habit that forward jos...   \n",
       "4                        im bors resta (istanbul turkey)   \n",
       "...                                                  ...   \n",
       "49913               list candid endors prim avail somewh   \n",
       "49914           easy push button today scorpio t scorpio   \n",
       "49915                        vint photos: patio look 40s   \n",
       "49916  weird im virgin mary appear yb diner: custom r...   \n",
       "49917                            cut sick #cat #blackcat   \n",
       "\n",
       "                    hashtags  \n",
       "0                         []  \n",
       "1                         []  \n",
       "2                         []  \n",
       "3                         []  \n",
       "4                         []  \n",
       "...                      ...  \n",
       "49913                     []  \n",
       "49914                     []  \n",
       "49915                     []  \n",
       "49916                     []  \n",
       "49917  ['#cat', '#blackcat']  \n",
       "\n",
       "[49918 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7a5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['type'] == 'tweet']\n",
    "# data = data[data['lang'] == 'en']\n",
    "# data.index = range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f67f79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stemmer = LancasterStemmer()\n",
    "\n",
    "# def remove_emojis(data):\n",
    "#     emoj = re.compile(\"[\"\n",
    "#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#         u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "#         u\"\\U00002702-\\U000027B0\"\n",
    "#         u\"\\U00002702-\\U000027B0\"\n",
    "#         u\"\\U000024C2-\\U0001F251\"\n",
    "#         u\"\\U0001f926-\\U0001f937\"\n",
    "#         u\"\\U00010000-\\U0010ffff\"\n",
    "#         u\"\\u2640-\\u2642\" \n",
    "#         u\"\\u2600-\\u2B55\"\n",
    "#         u\"\\u200d\"\n",
    "#         u\"\\u23cf\"\n",
    "#         u\"\\u23e9\"\n",
    "#         u\"\\u231a\"\n",
    "#         u\"\\ufe0f\"  # dingbats\n",
    "#         u\"\\u3030\"\n",
    "#                       \"]+\", re.UNICODE)\n",
    "#     return re.sub(emoj, '', data)\n",
    "\n",
    "# def stem_sentence(text):\n",
    "#     text = [stemmer.stem(word) for word in text.split()]\n",
    "    \n",
    "#     return ' '.join(text)\n",
    "    \n",
    "    \n",
    "# data['clean_text'] = data['text'].apply(lambda x: ntx.remove_stopwords(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_userhandles(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_urls(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_punctuations(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_multiple_spaces(x))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: remove_emojis(x))\n",
    "\n",
    "# data['hashtags'] = data['clean_text'].apply(lambda x: ntx.extract_hashtags(x))\n",
    "# # data['clean_text'] = data['clean_text'].apply(lambda x: ntx.remove_hashtags(x))\n",
    "\n",
    "# data['clean_text'] = data['clean_text'].apply(lambda x: stem_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee966eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign petit cal rish sunak priorit struggling cost liv giv bank big bonus ad nam\n",
      "I just signed the petition calling on Rishi Sunak to prioritise those of us struggling with the cost of living, rather than giving bankers bigger bonuses. Will you add your name? https://t.co/wJ6yraDzWv\n"
     ]
    }
   ],
   "source": [
    "print(data['clean_text'][0])\n",
    "print(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb235f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean text: 11944 sentences with numbers\n",
      "Text: 27607 sentences with numbers\n"
     ]
    }
   ],
   "source": [
    "def number_in_text(text, number):\n",
    "    for i in number:\n",
    "        if i in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "a = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print('Clean text:', data['clean_text'].apply(lambda x: number_in_text(x,a)).sum(), 'sentences with numbers')\n",
    "print('Text:', data['text'].apply(lambda x: number_in_text(x,a)).sum(), 'sentences with numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87062154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# less_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# ind = np.random.randint(0, data.index[-1]+1, 50000)\n",
    "# less_data = data.loc[ind]\n",
    "\n",
    "# less_data.to_csv('datasets/less_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2068ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['retweet_count', 'like_count', 'quote_count']].copy()\n",
    "y['retweets'] = y['retweet_count'] + y['quote_count']\n",
    "y.drop(['retweet_count', 'quote_count'], axis=1, inplace=True)\n",
    "\n",
    "x_col = ['followers_count', 'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177735bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TEXT\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorized_text = vectorizer.fit_transform(data['clean_text'])\n",
    "vectorized_text = vectorized_text.astype(np.float32)\n",
    "vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "\n",
    "# vectorizer = CountVectorizer(binary=True, dtype=np.int32)\n",
    "\n",
    "# vectorized_text = vectorizer.fit_transform(data['clean_text']).toarray()\n",
    "vectorized_text_with_followers = np.insert(vectorized_text, 0, data['followers_count'], axis=1) \n",
    "del vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1fee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_of_text = vectorized_text.shape[-1]\n",
    "# for i in range(shape_of_text):\n",
    "#     data[i] = vectorized_text[:, i]\n",
    "#     vectorized_text = vectorized_text[:, i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# names = vectorizer.get_feature_names_out()\n",
    "# while True:\n",
    "#     print(names[j])\n",
    "#     if j == 10000:\n",
    "#         break\n",
    "#     j += 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c9e58",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf164b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet()\n",
    "model.fit(vectorized_text_with_followers, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01903096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "# model.fit(vectorized_text_with_followers, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load('filename.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da07ff",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc148aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1252375  -0.52877533]]\n",
      "id                                                          69234701\n",
      "text_id                                                   7003688037\n",
      "text               @geniliad A VERY VERY HAPY XMAS !!!!!!!!!!!!!!...\n",
      "retweet_count                                                      0\n",
      "reply_count                                                        0\n",
      "like_count                                                         0\n",
      "quote_count                                                        0\n",
      "lang                                                              en\n",
      "type                                                           tweet\n",
      "post_created_at                            2009-12-24 16:18:31+00:00\n",
      "followers_count                                                   17\n",
      "statuses_count                                                    42\n",
      "friends_count                                                     91\n",
      "info_tweet                                                         0\n",
      "followers_group                                                  Low\n",
      "clean_text                  hapy xma onnon 2 u nd ur famy sur ul fun\n",
      "hashtags                                                          []\n",
      "Name: 1092, dtype: object\n",
      "like_count    0\n",
      "retweets      0\n",
      "Name: 1092, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n = 1092\n",
    "\n",
    "print(model.predict(vectorized_text_with_followers[n][np.newaxis, :]))\n",
    "print(data.loc[n])\n",
    "print(y.loc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5602bdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22603536062221866"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['info_tweet'] > 0]) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5b870",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK BAD IDEA, BECAUSE WE NEED SUCH A POWER COMPUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344d6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, return_sequences=True, input_shape=(1, vectorized_text.shape[-1])))\n",
    "# model.add(LSTM(50))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6316d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d5d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1559/1559 [==============================] - 69s 42ms/step - loss: 761319.4375\n",
      "Epoch 2/15\n",
      " 453/1559 [=======>......................] - ETA: 45s - loss: 203298.9375"
     ]
    }
   ],
   "source": [
    "# model.fit(vectorized_text[:, np.newaxis, :], y, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ff723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58ecde",
   "metadata": {},
   "source": [
    "## HASHTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take_unique_hashtags(ser):\n",
    "#     unique = []\n",
    "#     for lis in ser:\n",
    "#         for hashtag in lis:\n",
    "#             if hashtag not in unique:\n",
    "#                 unique.append(hashtag)\n",
    "    \n",
    "#     return unique\n",
    "\n",
    "# data['hashtags'] = clear_hashtags(data['hashtags'].copy())\n",
    "# unique_hashtags = take_unique_hashtags(data['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2075ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ########## HASHTAGS\n",
    "\n",
    "\n",
    "# vectorize_hash = TfidfVectorizer()\n",
    "\n",
    "# # vectorized_hash_fited = vectorize_hash.fit_transform(data['hashtags'])\n",
    "# # vectorized_hash_fited = vectorized_hash_fited.astype(np.float16)\n",
    "# # vectorized_hash_fited = vectorized_hash_fited.toarray()\n",
    "\n",
    "# vectorize_hash.fit(unique_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_of_hash_uniq = len(vectorize_hash.get_feature_names_out())\n",
    "\n",
    "# def convert_hashtag_to_vector(hashtags, vectorizer, len_of_features):\n",
    "#     ones = np.ones((len_of_features))\n",
    "#     if len(hashtags) == 1:\n",
    "#         ind = np.argmax(vectorizer.transform(hashtags))\n",
    "#         ones[ind] = 1\n",
    "#     elif len(hashtags) >= 2:\n",
    "#         indexes = []\n",
    "#         for hashtag in hashtags:\n",
    "#             indexes.append(np.argmax(vectorizer.transform([hashtag])))\n",
    "#         for index in indexes:\n",
    "#             ones[index] = 1\n",
    "        \n",
    "#     return ones\n",
    "\n",
    "        \n",
    "# # vectorize_hash.transform(['#hello']).toarray()\n",
    "# data['hashtags'] = data['hashtags'].apply(lambda x: convert_hashtag_to_vector(x, vectorize_hash, len_of_hash_uniq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
